{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from requests import get\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseTypes = []\n",
    "streetAddresses = []\n",
    "zipcodes = []\n",
    "cities = []\n",
    "states= []\n",
    "baths= []\n",
    "beds_list = []\n",
    "area_list = []\n",
    "house_prices= []\n",
    "house_url_list=[]\n",
    "url_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ziplist=[\"63141\",\"63105\",\"63135\",\"63131\",\"63124\",\"63304\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.realtor.com/realestateandhomes-search/63141/pg-0\n",
      "https://www.realtor.com/realestateandhomes-search/63141/pg-1\n",
      "https://www.realtor.com/realestateandhomes-search/63141/pg-2\n",
      "total no of houses scraped 807\n",
      "https://www.realtor.com/realestateandhomes-search/63105/pg-0\n",
      "https://www.realtor.com/realestateandhomes-search/63105/pg-1\n",
      "https://www.realtor.com/realestateandhomes-search/63105/pg-2\n",
      "total no of houses scraped 939\n",
      "https://www.realtor.com/realestateandhomes-search/63135/pg-0\n",
      "https://www.realtor.com/realestateandhomes-search/63135/pg-1\n",
      "https://www.realtor.com/realestateandhomes-search/63135/pg-2\n",
      "None type object exception\n",
      "total no of houses scraped 1071\n",
      "https://www.realtor.com/realestateandhomes-search/63131/pg-0\n",
      "index out of range\n",
      "index out of range\n",
      "https://www.realtor.com/realestateandhomes-search/63131/pg-1\n",
      "index out of range\n",
      "index out of range\n",
      "https://www.realtor.com/realestateandhomes-search/63131/pg-2\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 1203\n",
      "https://www.realtor.com/realestateandhomes-search/63124/pg-0\n",
      "index out of range\n",
      "index out of range\n",
      "https://www.realtor.com/realestateandhomes-search/63124/pg-1\n",
      "index out of range\n",
      "index out of range\n",
      "https://www.realtor.com/realestateandhomes-search/63124/pg-2\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 1335\n",
      "https://www.realtor.com/realestateandhomes-search/63304/pg-0\n",
      "https://www.realtor.com/realestateandhomes-search/63304/pg-1\n",
      "https://www.realtor.com/realestateandhomes-search/63304/pg-2\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 1467\n"
     ]
    }
   ],
   "source": [
    "for i in ziplist:\n",
    "    house=1\n",
    "    zipurl='https://www.realtor.com/realestateandhomes-search/'+ i\n",
    "    for  page in range(0,3):\n",
    "\n",
    "            url= zipurl +'/pg-'+ str(page)\n",
    "            print(url)\n",
    "            r=get(url,headers=headers)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            lis=soup.find_all('li', class_='component_property-card')\n",
    "\n",
    "\n",
    "            for li in lis:\n",
    "                #Get house links\n",
    "                anchor=li.find('a')\n",
    "                if anchor is not None:\n",
    "                    house_url = anchor.get('href','')\n",
    "                    house = house+1\n",
    "                    url_list.append(house_url)\n",
    "                    \n",
    "                card_box=li.find('div',class_='card-box')\n",
    "                if card_box is not None:\n",
    "                    #Get house price  \n",
    "                    house_price=(card_box.find('span',class_='data-price')).text\n",
    "                    house_prices.append(house_price)\n",
    "                    \n",
    "                    #get house type\n",
    "                    house_type=(card_box.find('div',class_='property-type')).text\n",
    "                    houseTypes.append(house_type)\n",
    "                    \n",
    "                    #get  Street Address\n",
    "                    try:\n",
    "                        street_address=(card_box.find('span', class_='listing-street-address')).text\n",
    "                    except AttributeError:\n",
    "                        print(\"None type object exception\")\n",
    "                        street_address=\"NA\"\n",
    "                    streetAddresses.append(street_address)\n",
    "\n",
    "                    #City\n",
    "                    city=(card_box.find('span', class_='listing-city')).text\n",
    "                    cities.append(city)\n",
    "\n",
    "                    #State\n",
    "                    state=(card_box.find('span', class_='listing-region')).text\n",
    "                    states.append(state)\n",
    "                    \n",
    "                    #zipcode\n",
    "                    zipcode=(card_box.find('span', class_='listing-postal')).text\n",
    "                    zipcodes.append(zipcode)\n",
    "                    \n",
    "                    # property details\n",
    "                    meta_data=card_box.find_all('span',class_='data-value')\n",
    "                    if len(meta_data)>0:\n",
    "                          # no of beds\n",
    "                        try:    \n",
    "                            beds =meta_data[0].text\n",
    "                        except:\n",
    "                            print(\"index out of range\")\n",
    "                            beds=0\n",
    "                        #no of baths\n",
    "                        try:\n",
    "                            bath= meta_data[1].text\n",
    "                        except:\n",
    "                            print(\"index out of range\")\n",
    "                            bath=0\n",
    "                        try:\n",
    "                            sqft= meta_data[2].text\n",
    "                        except:\n",
    "                            print(\"index out of range\")\n",
    "                            sqft=0\n",
    "                        beds_list.append(beds)\n",
    "                        baths.append(bath)\n",
    "                        area_list.append(sqft)\n",
    "                        \n",
    "                    else:\n",
    "                        beds=0\n",
    "                        bath=0\n",
    "                        sqft=0\n",
    "                        beds_list.append(beds)\n",
    "                        baths.append(bath)\n",
    "                        area_list.append(sqft)\n",
    "                    \n",
    "\n",
    "\n",
    "            house_url_list=['https://www.realtor.com/'+url for url in url_list]\n",
    "            \n",
    "            house_data=list(zip(houseTypes, house_prices,streetAddresses,cities,states,zipcodes,area_list,beds_list,baths))\n",
    "    sleep(randint(1,2))  \n",
    "    print(f\"total no of houses scraped {house}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housetype length:1466\n",
      "price length:1466\n",
      "st length:1421\n",
      "city length:1421\n",
      "state length:1421\n",
      "Zip length:1421\n",
      "size length:1419\n",
      "beds length:1419\n",
      "baths length:1419\n"
     ]
    }
   ],
   "source": [
    "print(f\"Housetype length:{len(houseTypes)}\")\n",
    "print(f\"price length:{len(house_prices)}\")\n",
    "print(f\"st length:{len(streetAddresses)}\")\n",
    "print(f\"city length:{len(cities)}\")\n",
    "print(f\"state length:{len(states)}\")\n",
    "print(f\"Zip length:{len(zipcodes)}\")\n",
    "print(f\"size length:{len(area_list)}\")\n",
    "print(f\"beds length:{len(beds_list)}\")\n",
    "print(f\"baths length:{len(baths)}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = []\n",
    "url_list = []\n",
    "book_url_list = []\n",
    "for category in categories:\n",
    "    title = category.text.strip()\n",
    "    print(title)\n",
    "    category_list.append(title)\n",
    "    book_url = category.find('a')['href']\n",
    "    url_list.append(book_url)\n",
    "\n",
    "book_url_list = ['http://books.toscrape.com/' + url for url in url_list]\n",
    "\n",
    "titles_and_urls = zip(category_list, book_url_list)\n",
    " try:\n",
    "    for title_url in titles_and_urls:\n",
    "        browser.click_link_by_partial_text('next')\n",
    "except ElementDoesNotExist:\n",
    "    print(\"Scraping Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " house_url_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
