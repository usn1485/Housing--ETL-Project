{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from requests import get\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseTypes = []\n",
    "streetAddresses = []\n",
    "zipcodes = []\n",
    "cities = []\n",
    "states= []\n",
    "baths= []\n",
    "beds_list = []\n",
    "area_list = []\n",
    "house_prices= []\n",
    "house_url_list=[]\n",
    "url_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ziplist=[\"63011\",\"63026\",\"63108\",\"63126\",\"63017\",\"63304\",\"63108\",\"63130\",\"63764\",\"63114\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of houses scraped 133\n",
      "None type object exception\n",
      "total no of houses scraped 133\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 133\n",
      "None type object exception\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "None type object exception\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 96\n",
      "None type object exception\n",
      "total no of houses scraped 133\n",
      "total no of houses scraped 133\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 133\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 133\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 90\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "index out of range\n",
      "total no of houses scraped 133\n"
     ]
    }
   ],
   "source": [
    "for i in ziplist:\n",
    "    house=1\n",
    "    zipurl='https://www.realtor.com/realestateandhomes-search/'+ i\n",
    "    for  page in range(0,3):\n",
    "\n",
    "            url= zipurl +'/pg-'+ str(page)\n",
    "            #print(url)\n",
    "            r=get(url,headers=headers)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            lis=soup.find_all('li', class_='component_property-card')\n",
    "\n",
    "\n",
    "            for li in lis:\n",
    "                #Get house links\n",
    "                anchor=li.find('a')\n",
    "                if anchor is not None:\n",
    "                    house_url = anchor.get('href','')\n",
    "                    house = house+1\n",
    "                    url_list.append(house_url)\n",
    "                    \n",
    "                card_box=li.find('div',class_='card-box')\n",
    "                if card_box is not None:\n",
    "                    #Get house price  \n",
    "                    house_price=(card_box.find('span',class_='data-price')).text\n",
    "                    house_prices.append(house_price)\n",
    "                    \n",
    "                    #get house type\n",
    "                    house_type=(card_box.find('div',class_='property-type')).text\n",
    "                    houseTypes.append(house_type)\n",
    "                    \n",
    "                    #get  Street Address\n",
    "                    try:\n",
    "                        street_address=(card_box.find('span', class_='listing-street-address')).text\n",
    "                        street_address=street_address.strip()\n",
    "                    except AttributeError:\n",
    "                        print(\"None type object exception\")\n",
    "                        street_address=\"NA\"\n",
    "                    streetAddresses.append(street_address)\n",
    "\n",
    "                    #City\n",
    "                    city=(card_box.find('span', class_='listing-city')).text\n",
    "                    cities.append(city)\n",
    "\n",
    "                    #State\n",
    "                    state=(card_box.find('span', class_='listing-region')).text\n",
    "                    states.append(state)\n",
    "                    \n",
    "                    #zipcode\n",
    "                    zipcode=(card_box.find('span', class_='listing-postal')).text\n",
    "                    zipcodes.append(zipcode)\n",
    "                    \n",
    "                    # property details\n",
    "                    meta_data=card_box.find_all('span',class_='data-value')\n",
    "                    if len(meta_data)>0:\n",
    "                          # no of beds\n",
    "                        try:    \n",
    "                            beds =meta_data[0].text\n",
    "                        except:\n",
    "                            print(\"index out of range\")\n",
    "                            beds=0\n",
    "                        #no of baths\n",
    "                        try:\n",
    "                            bath= meta_data[1].text\n",
    "                        except:\n",
    "                            print(\"index out of range\")\n",
    "                            bath=0\n",
    "                        try:\n",
    "                            sqft= meta_data[2].text\n",
    "                        except:\n",
    "                            print(\"index out of range\")\n",
    "                            sqft=0\n",
    "                        beds_list.append(beds)\n",
    "                        baths.append(bath)\n",
    "                        area_list.append(sqft)\n",
    "                        \n",
    "                    else:\n",
    "                        beds=0\n",
    "                        bath=0\n",
    "                        sqft=0\n",
    "                        beds_list.append(beds)\n",
    "                        baths.append(bath)\n",
    "                        area_list.append(sqft)\n",
    "                    \n",
    "\n",
    "\n",
    "            house_url_list=['https://www.realtor.com/'+url for url in url_list]\n",
    "            \n",
    "            house_data=list(zip(houseTypes, house_prices,streetAddresses,cities,states,zipcodes,area_list,beds_list,baths,house_url_list))\n",
    "    sleep(randint(1,2))  \n",
    "    print(f\"total no of houses scraped {house}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housetype length:1240\n",
      "price length:1240\n",
      "st length:1240\n",
      "city length:1240\n",
      "state length:1240\n",
      "Zip length:1240\n",
      "size length:1240\n",
      "beds length:1240\n",
      "baths length:1240\n",
      "Links length:1240\n"
     ]
    }
   ],
   "source": [
    "print(f\"Housetype length:{len(houseTypes)}\")\n",
    "print(f\"price length:{len(house_prices)}\")\n",
    "print(f\"st length:{len(streetAddresses)}\")\n",
    "print(f\"city length:{len(cities)}\")\n",
    "print(f\"state length:{len(states)}\")\n",
    "print(f\"Zip length:{len(zipcodes)}\")\n",
    "print(f\"size length:{len(area_list)}\")\n",
    "print(f\"beds length:{len(beds_list)}\")\n",
    "print(f\"baths length:{len(baths)}\")\n",
    "print(f\"Links length:{len(house_url_list)}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Scraped_houses.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f5031a800095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mRealtor_houses_DF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhouse_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mRealtor_houses_DF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scraped_houses.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Scraped_houses.csv'"
     ]
    }
   ],
   "source": [
    "cols=['Property Types', 'Price','Street Addresses','City','State','Zipcode','Sqft Area','Beds','Baths',\"Links\"]\n",
    "\n",
    "Realtor_houses_DF=pd.DataFrame(house_data,columns=cols)\n",
    "Realtor_houses_DF.to_csv(\"Scraped_houses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
